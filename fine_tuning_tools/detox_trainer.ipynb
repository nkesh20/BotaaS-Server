{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Language Detection with XLM-RoBERTa (Regression)\n",
    "\n",
    "This notebook trains an XLM-RoBERTa model to detect toxic language in text, outputting a score from 0 to 1 indicating how unacceptable the text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:33:06.161514Z",
     "iopub.status.busy": "2025-07-28T08:33:06.160925Z",
     "iopub.status.idle": "2025-07-28T08:36:42.992801Z",
     "shell.execute_reply": "2025-07-28T08:36:42.991767Z",
     "shell.execute_reply.started": "2025-07-28T08:33:06.161488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch scikit-learn pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:36:49.241714Z",
     "iopub.status.busy": "2025-07-28T08:36:49.240763Z",
     "iopub.status.idle": "2025-07-28T08:37:14.997048Z",
     "shell.execute_reply": "2025-07-28T08:37:14.996206Z",
     "shell.execute_reply.started": "2025-07-28T08:36:49.241660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel, PreTrainedModel, AutoConfig, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:37:18.055514Z",
     "iopub.status.busy": "2025-07-28T08:37:18.054603Z",
     "iopub.status.idle": "2025-07-28T08:37:20.807009Z",
     "shell.execute_reply": "2025-07-28T08:37:20.806099Z",
     "shell.execute_reply.started": "2025-07-28T08:37:18.055487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"Tokenizer loaded: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:37:23.384600Z",
     "iopub.status.busy": "2025-07-28T08:37:23.384282Z",
     "iopub.status.idle": "2025-07-28T08:37:23.391023Z",
     "shell.execute_reply": "2025-07-28T08:37:23.390166Z",
     "shell.execute_reply.started": "2025-07-28T08:37:23.384578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataset for Regression\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, texts, scores, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.scores = scores\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        score = float(self.scores[idx])\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(score, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:37:26.512367Z",
     "iopub.status.busy": "2025-07-28T08:37:26.512074Z",
     "iopub.status.idle": "2025-07-28T08:37:36.995823Z",
     "shell.execute_reply": "2025-07-28T08:37:36.994916Z",
     "shell.execute_reply.started": "2025-07-28T08:37:26.512345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ToxicRegressor(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = 1  # Single output for regression\n",
    "        self.bert = AutoModel.from_config(config)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "        self.post_init()  # âœ… ensures weights and config are set correctly\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Try pooler_output first, fallback to mean pooling if not available\n",
    "        pooled_output = getattr(outputs, \"pooler_output\", None)\n",
    "        if pooled_output is None:\n",
    "            pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.regressor(pooled_output)\n",
    "        \n",
    "        # Apply sigmoid to ensure output is between 0 and 1\n",
    "        predictions = torch.sigmoid(logits).squeeze(-1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Use MSE loss for regression\n",
    "            loss_fct = nn.MSELoss()\n",
    "            loss = loss_fct(predictions, labels)\n",
    "\n",
    "        return (loss, predictions) if loss is not None else predictions\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=1)\n",
    "model = ToxicRegressor(config)\n",
    "model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:40:26.979432Z",
     "iopub.status.busy": "2025-07-28T08:40:26.978695Z",
     "iopub.status.idle": "2025-07-28T08:40:27.059120Z",
     "shell.execute_reply": "2025-07-28T08:40:27.058270Z",
     "shell.execute_reply.started": "2025-07-28T08:40:26.979409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"score_train_new.csv\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "# Shuffle the rows\n",
    "shuffled_df = df_unique.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Extract texts and scores\n",
    "texts = shuffled_df['label'].values  # 'label' column contains the text\n",
    "scores = shuffled_df['score'].values  # 'score' column contains the toxicity score\n",
    "\n",
    "# Convert scores to float\n",
    "scores = scores.astype(float)\n",
    "\n",
    "print(f\"Dataset loaded: {len(texts)} samples\")\n",
    "print(f\"Score range: {scores.min():.4f} to {scores.max():.4f}\")\n",
    "print(f\"Mean score: {scores.mean():.4f}\")\n",
    "print(f\"Std score: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:40:48.488891Z",
     "iopub.status.busy": "2025-07-28T08:40:48.488457Z",
     "iopub.status.idle": "2025-07-28T08:40:48.503299Z",
     "shell.execute_reply": "2025-07-28T08:40:48.502240Z",
     "shell.execute_reply.started": "2025-07-28T08:40:48.488861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_texts, val_texts, train_scores, val_scores = train_test_split(\n",
    "    texts, scores, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ToxicDataset(train_texts, train_scores, tokenizer, MAX_LENGTH)\n",
    "val_dataset = ToxicDataset(val_texts, val_scores, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:41:14.450894Z",
     "iopub.status.busy": "2025-07-28T08:41:14.449995Z",
     "iopub.status.idle": "2025-07-28T08:41:14.466144Z",
     "shell.execute_reply": "2025-07-28T08:41:14.465285Z",
     "shell.execute_reply.started": "2025-07-28T08:41:14.450857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            loss, preds = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_scores.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mse = mean_squared_error(true_scores, predictions)\n",
    "    mae = mean_absolute_error(true_scores, predictions)\n",
    "    r2 = r2_score(true_scores, predictions)\n",
    "    \n",
    "    return total_loss / len(dataloader), mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T08:41:17.231810Z",
     "iopub.status.busy": "2025-07-28T08:41:17.231460Z",
     "iopub.status.idle": "2025-07-28T08:59:11.805597Z",
     "shell.execute_reply": "2025-07-28T08:59:11.804700Z",
     "shell.execute_reply.started": "2025-07-28T08:41:17.231790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_r2 = -float('inf')\n",
    "training_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_mse, val_mae, val_r2 = evaluate(model, val_loader, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val MSE: {val_mse:.4f}\")\n",
    "    print(f\"Val MAE: {val_mae:.4f}\")\n",
    "    print(f\"Val RÂ²: {val_r2:.4f}\")\n",
    "    \n",
    "    training_history.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_mse': val_mse,\n",
    "        'val_mae': val_mae,\n",
    "        'val_r2': val_r2\n",
    "    })\n",
    "    \n",
    "    if val_r2 > best_r2:\n",
    "        best_r2 = val_r2\n",
    "        torch.save(model.state_dict(), 'best_toxic_regression_model.pth')\n",
    "        print(\"New best model saved!\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:01:19.114388Z",
     "iopub.status.busy": "2025-07-28T09:01:19.113615Z",
     "iopub.status.idle": "2025-07-28T09:01:47.678706Z",
     "shell.execute_reply": "2025-07-28T09:01:47.677769Z",
     "shell.execute_reply.started": "2025-07-28T09:01:19.114362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_toxic_regression_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Final evaluation\n",
    "val_loss, val_mse, val_mae, val_r2 = evaluate(model, val_loader, device)\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"MSE: {val_mse:.4f}\")\n",
    "print(f\"MAE: {val_mae:.4f}\")\n",
    "print(f\"RÂ² Score: {val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prediction function for regression\n",
    "def predict_toxic_score(text, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        score = predictions.item()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Test predictions\n",
    "test_texts = [\n",
    "    \"This is a normal message\",\n",
    "    \"You are stupid and worthless\",\n",
    "    \"Have a great day!\",\n",
    "    \"I hate you so much\",\n",
    "    \"Thanks for your help\",\n",
    "    \"You're a complete idiot and I hope you fail\",\n",
    "    \"The weather is nice today\",\n",
    "    \"Go to hell you worthless piece of trash\"\n",
    "]\n",
    "\n",
    "print(\"\\nTest Predictions:\")\n",
    "for text in test_texts:\n",
    "    score = predict_toxic_score(text, model, tokenizer, device)\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Toxicity Score: {score:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:01:58.111168Z",
     "iopub.status.busy": "2025-07-28T09:01:58.110885Z",
     "iopub.status.idle": "2025-07-28T09:02:01.173140Z",
     "shell.execute_reply": "2025-07-28T09:02:01.172200Z",
     "shell.execute_reply.started": "2025-07-28T09:01:58.111149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./toxic_regression_model\")\n",
    "tokenizer.save_pretrained(\"./toxic_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:02:06.375141Z",
     "iopub.status.busy": "2025-07-28T08:37:26.512074Z",
     "iopub.status.idle": "2025-07-28T08:37:36.995823Z",
     "shell.execute_reply": "2025-07-28T08:37:36.994916Z",
     "shell.execute_reply.started": "2025-07-28T08:37:26.512345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:02:13.447903Z",
     "iopub.status.busy": "2025-07-28T08:37:26.512074Z",
     "iopub.status.idle": "2025-07-28T08:37:26.512345Z",
     "shell.execute_reply": "2025-07-28T08:37:26.512345Z",
     "shell.execute_reply.started": "2025-07-28T08:37:26.512345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:03:40.114296Z",
     "iopub.status.busy": "2025-07-28T08:37:26.512074Z",
     "iopub.status.idle": "2025-07-28T08:37:26.512345Z",
     "shell.execute_reply": "2025-07-28T08:37:26.512345Z",
     "shell.execute_reply.started": "2025-07-28T08:37:26.512345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=\"chalique/detox-regression\", repo_type=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T09:03:43.019741Z",
     "iopub.status.busy": "2025-07-28T08:37:26.512074Z",
     "iopub.status.idle": "2025-07-28T08:37:26.512345Z",
     "shell.execute_reply": "2025-07-28T08:37:26.512345Z",
     "shell.execute_reply.started": "2025-07-28T08:37:26.512345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "api.upload_folder(\n",
    "    folder_path=\"./toxic_regression_model\",\n",
    "    repo_id=\"chalique/detox-regression\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7957364,
     "sourceId": 12598421,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}